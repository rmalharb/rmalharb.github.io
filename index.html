<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Rahaf Alharbi</title>
  <meta name="author" content="Rahaf Alharbi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>✨</text></svg>">
</head>
<body>
  <div style="max-width: 800px; margin: 0 auto;">
    <section class="title-section">
      <h1 class="large-title">Rahaf Alharbi</h1>
    </section>

    <section>
     <!--  <h1>About Me</h1>  -->
      <!-- Content about yourself goes here -->
      <div style="display: flex; align-items: center;">
        <div style="flex: 1;">
          <p style="text-align:center;">
          </p>
          <p>I am a Ph.D. candidate in  <a href="https://www.si.umich.edu/">the School of Information</a> at the <a href="https://umich.edu/">University of Michigan</a> where I am luckily  advised by <a href="https://robinbrewer.com/">Dr. Robin Brewer</a> and <a href="https://yardi.people.si.umich.edu/">Dr. Sarita Schoenebeck</a>. My research is at the intersection of accessibility, privacy, and AI/ML. I draw from disability studies and empirical research with Blind and low vision communities to inform the design of responsible, accessible, explainable, and privacy-aware AI/ML technologies. My research appeared in top-tier computing venues such as ACM CHI, CSCW, and First Monday. 
          </p>
          <p>
            Prior to graduate school, I obtained my Bachelor of Science degree in Mechanical Engineering (minor in Ethnic Studies) at the <a href="https://www.ucsd.edu/">University of California, San Diego</a>.
          </p>
          <p>
            I interned at <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a> with the <a href="https://www.microsoft.com/en-us/research/group/ability/">Ability team</a>. Most recently in summer 2023, I interned at <a href="https://www.meta.com">Meta</a> with the <a href="https://ai.meta.com/responsible-ai/">Responsible AI team</a>. 
          </p>
          <p style="text-align:center">
            <a href="mailto:rmalharb@umich.edu">Email</a> &nbsp;/&nbsp;
            <a href="data/Rahaf_cv.pdf">CV</a> &nbsp;/&nbsp;
            <a href="https://scholar.google.com/citations?hl=en&user=mefIyhYAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp;/&nbsp;
            <a href="https://twitter.com/rmalharb">Twitter</a>
          </p>
        </div>
        <div style="flex: 1;margin-left: 20px; margin-bottom: 20px;">
          <img style="width:75%;max-width:75%" alt="Rahaf looking straight to the camera and smiling. She is wearing a black t-shirt and standing behind green plants. Rahaf used to have long black hair with dyed maroon ends." src="images/profile_photo.jpg" class="hoverZoomLink">
        </div>
      </div>
    </section>
    
    <section>
      <h1>Updates</h1>
      <ul>
        <li>
          <strong>Aug. 2023:</strong> Our  <a href="https://sites.google.com/umich.edu/privacya11y/home?pli=1">privacy and accessibility</a> workshop was accepted to ASSETS 2023!
        </li>
        <li>
          <strong>May 2023:</strong> Started my internship at Meta in the Responsible AI team! I am excited to be back in California!
        </li>
        <li>
          <strong>Mar. 2023:</strong> Excited to present our paper “Accessibility Barriers, Conflicts, and Repairs: Understanding the Experience of Professionals with Disabilities in Hybrid Meetings” at CHI 2023 in Hamburg, Germany.
        </li>
        <li>
          <strong>Dec. 2022:</strong> I passed my prelim defense! I’m now a Ph.D. candidate!
        </li>
        <li>
          <strong>May 2022:</strong> I started my internship at Microsoft Research in the Ability team!
        </li>
        <li>
          <strong>Apr. 2022:</strong> My first first-author paper was accepted to CSCW 2022! Excited to present my study on the benefits and harms that Blind people perceive of future privacy technology (obfuscation).
        </li>
        <li>
          <strong>Nov. 2022:</strong> I passed my pre-candidacy defense!
        </li>
      </ul>
    </section>
    
    <section>
      <h1>Journal and Conference Publications</h1> <h2>(rigorously peer-reviewed and archived)</h2>
       <article class="publication">
    <div style="display: flex; align-items: center;">
      <div style="flex: 1; padding: 20px;">
        <img src="images/P21_exp_2.jpg" alt="Illustration of Deaf ASL user that has a laptop and a mobile device setup. On the laptop, there is a video conferencing interface that shows the video grid of in-person attendees and three other remote attendees. Also, there is a mobile device, standing upright, with a video image of an ASL interpreter." width="240" style="border-style: none;">
      </div>
      <div style="flex: 2;">
        <h3>Accessibility Barriers, Conflicts, and Repairs: Understanding the Experience of Professionals with Disabilities in Hybrid Meetings</h3>
        <p><strong>Rahaf Alharbi</strong>, John Tang, Karl Henderson</p>
        <p><em>CHI 2023</em></p>
        <a href="data/accessible_chi23-846.pdf">PDF</a> /
        <a href="https://dl.acm.org/doi/10.1145/3544548.3581541">ACM DL</a> /
        <a href="https://www.youtube.com/watch?v=FtMdTMvDSbE">Talk</a>
        <p>We interviewed 21 professionals with disabilities to unpack the accessibility dimensions of hybrid meetings, highlighting the creative ways professionals with disabilities developed workarounds and repairs to these accessibility tensions. In the paper, we discuss how invisible and visible access labor may support or undermine accessibility in hybrid meetings. We also argue that hybrid meetings are an important accessibility resource. Building from our analysis, we offer practical suggestions and design directions to make hybrid meetings accessible.</p>
      </div>
    </div>
  </article>
  
   <article class="publication">
    <div style="display: flex; align-items: center;">
      <div style="flex: 1; padding: 20px;">
        <img src="images/CHI2023_DIY_AT.jpg" alt="Illustration of participant trying to use Seeing AI to read mail, but they frustrated because Seeing AI keeps repeating the same information as they slightly shift their camera" width="240" style="border-style: none;">
      </div>
      <div style="flex: 2;">
        <h3>Hacking, Switching, Combining: Understanding and Supporting DIY Assistive Technology Design by Blind People</h3>
        <p>Jaylin Herskovitz, Andi Xu, <strong>Rahaf Alharbi</strong>, Anhong Guo</p>
        <p><em>CHI 2023</em></p>
        <a href="data/CHI2023_DIY_AT.pdf">PDF</a> /
        <a href="https://dl.acm.org/doi/10.1145/3543216.3545660">ACM DL</a> /
        <a href="https://www.youtube.com/watch?v=6JcgFpf1edE">Talk</a> /
        <a href="https://github.com/HumanAILab/diy-a11y">Dataset</a>
        <p>Current assistive technologies (AT) often fail to support the unique needs of Blind people, so they may need to become domain experts, 'hack' and create Do-it-Yourself (DIY) AT to creatively suit their need. To further understand and support DIY AT, we conducted two-stage interviews and diary study with 12 Blind participants. We found that current DIY AT is created both implicitly through creative use cases, and explicitly via ideation and development. From our results, we present design considerations for future DIY technology systems to support existing customization and ‘hacking’ behaviors Blind people develop.</p>
      </div>
    </div>
  </article>


<article class="publication">
    <div style="display: flex; align-items: center;">
      <div style="flex: 1; padding: 20px;">
        <img src="images/firstmonday.jpg" alt="First Monday logo" width="240" style="border-style: none;">
      </div>
      <div style="flex: 2;">
        <h3>Definition Drives Design: Disability Models and Mechanisms of Bias in AI Technologies</h3>
        <p>Denis Newman-Griffis, Jessica Sage Rauchberg, <strong>Rahaf Alharbi</strong>, Louise Hickman, Harry Hochheiser</p>
        <p><em>First Monday</em></p>
        <a href="data/newm.pdf">PDF</a> /
        <a href="https://firstmonday.org/ojs/index.php/fm/article/view/12903">First Monday DL</a> /
        <p>We reveal how AI bias stems from various design choices, including problem definition, data selection, technology use, and operational elements, alongside core algorithms. We show that differing disability definitions drive distinct design decisions and AI biases. Lack of transparency and disabled involvement exacerbate these issues. Our analysis offers a framework for scrutinizing AI in decision-making and promotes disability-led design for equitable AI in disability contexts.</p>
      </div>
    </div>
  </article>


  <article class="publication">
    <div style="display: flex; align-items: center;">
      <div style="flex: 1; padding: 20px;">
        <img src="images/CSCWgif.gif" alt="GIF of a medicine bottle with the patient name being obfuscated by blurring" width="240" style="border-style: none;">
      </div>
      <div style="flex: 2;">
        <h3>Understanding Emerging Obfuscation Technologies in Visual Description Services for Blind and Low Vision People</h3>
        <p><strong>Rahaf Alharbi</strong>, Robin N. Brewer, Sarita Schoenebeck</p>
        <p><em>CSCW 2022</em></p>
        <a href="data/CSCW3555570.pdf">PDF</a> /
        <a href="https://dl.acm.org/doi/10.1145/3555570">ACM DL</a> /
        <a href="https://www.youtube.com/watch?v=Z-aRxKsN6J8">Talk</a> 
        <p>Machine learning approaches such as obfuscation are often thought of as the state-of-art solution to addressing visual privacy concerns that are rampant in visual assistance technologies. We interviewd 20 Blind and low vision people to understand their perspectives on obfuscation. We found that while there are some benefits to obfuscation such as gaining more agency and safeguarding against accidental privacy leaks, there are significant trust and accessibility issues. Further, participants worried that cultural or gendered privacy needs might be overlooked in obfuscation systems. We applied the framework of interdependence to rethink current obfuscation approaches, and provided more inclusive design directions.</p>
      </div>
    </div>
  </article>


  <article class="publication">
    <div style="display: flex; align-items: center;">
      <div style="flex: 1; padding: 20px;">
        <img src="images/cscwbw.jpg" alt="CSCW 2022 logo" width="240" style="border-style: none;">
      </div>
      <div style="flex: 2;">
        <h3>Women's Perspectives on Harm and Justice after Online Harassment</h3>
        <p>Jane Im, Sarita Schoenebeck, Marilyn Iriarte, Gabriel Grill, Daricia Wilkinson, Amna Batool, <strong>Rahaf Alharbi</strong>, Audrey N. Funwie, Tergel Gankhuu, Eric Gilbert, Mustafa Naseem</p>
        <p><em>CSCW 2022</em></p>
        <a href="data/CSCW3555775.pdf">PDF</a>
        <p>We conducted a survey in 14 geographic regions around the world (N = 3,993) to understand women’s perceptions of harm associated with online harassment and preferred platform responses to that harm.  Results show that, on average, women perceive greater harm associated with online harassment than men, especially for non-consensual image sharing.</p>
      </div>
    </div>
  </article>





    </section>
  </div>

  <footer style="text-align: center;">
  <p>&copy; 2023 Rahaf Alharbi. Original code by <a href="https://jonbarron.info">Jon Barron</a>, with accessibility changes by Rahaf Alharbi <a href="https://github.com/rmalharb/rmalharb.github.io">(source code)</a>.</p>
</footer>

</body>
</html>
